# ===========================================
# Discord Voice Bot Configuration
# ===========================================

# Discord Bot Token (required)
# Get it from: https://discord.com/developers/applications
DISCORD_TOKEN=your_discord_bot_token

# Discord Application ID (required for slash commands)
DISCORD_CLIENT_ID=your_application_id

# Optional: Restrict to specific guild during development
# DISCORD_GUILD_ID=your_guild_id

# Bot trigger words (comma-separated, for wake word detection)
BOT_TRIGGERS=hey bot,ok bot,computer

# ===========================================
# User Access Control
# ===========================================

# Owner ID (your Discord user ID - for OWNER_ONLY mode)
# OWNER_ID=your_discord_user_id

# Owner-only mode: only the owner can use voice features
# If OWNER_ID is not set, falls back to server owner
# OWNER_ONLY=true

# Allowlist: only these users can use voice features (comma-separated user IDs)
# If empty, everyone is allowed (unless blocked or OWNER_ONLY is set)
# ALLOWED_USERS=123456789,987654321

# Blocklist: these users are always blocked (comma-separated user IDs)
# BLOCKED_USERS=111111111,222222222

# ===========================================
# Text Bridge Configuration
# ===========================================

# Text channel where voice transcriptions are posted
# Both bots (Voice Bot and Responder) must have access to this channel
TEXT_CHANNEL_ID=your_text_channel_id

# User ID of the responder bot that will reply to transcriptions
# This is the Discord User ID (not Application ID) of your responder bot
RESPONDER_BOT_ID=your_responder_bot_user_id

# Timeout for waiting for a response (milliseconds)
RESPONSE_TIMEOUT=30000

# ===========================================
# Speech-to-Text (STT) Configuration
# ===========================================

# STT Provider: whisper-api | whisper-local
STT_PROVIDER=whisper-api

# Whisper API (OpenAI-compatible endpoint)
STT_API_URL=https://api.openai.com/v1/audio/transcriptions
STT_API_KEY=your_openai_api_key
STT_MODEL=whisper-1

# Whisper Local (for self-hosted whisper.cpp server)
# STT_API_URL=http://localhost:8080/inference
# STT_MODEL=base.en

# ===========================================
# Text-to-Speech (TTS) Configuration
# ===========================================

# TTS Provider: openai | sherpa-onnx | elevenlabs
TTS_PROVIDER=openai

# OpenAI TTS
TTS_API_URL=https://api.openai.com/v1/audio/speech
TTS_API_KEY=your_openai_api_key
TTS_MODEL=tts-1
TTS_VOICE=nova

# Sherpa-ONNX (local, free)
# TTS_API_URL=http://localhost:8787
# TTS_VOICE=thorsten

# ElevenLabs
# TTS_API_URL=https://api.elevenlabs.io/v1
# TTS_API_KEY=your_elevenlabs_api_key
# TTS_VOICE=your_voice_id

# ===========================================
# Voice Activity Detection (VAD)
# ===========================================

# Silence duration before processing (milliseconds)
VAD_SILENCE_DURATION=1500

# Minimum speech duration to process (milliseconds)
VAD_MIN_SPEECH_DURATION=500

# ===========================================
# Audio Settings
# ===========================================

# Audio sample rate (Discord uses 48000)
AUDIO_SAMPLE_RATE=48000

# Audio channels (1 = mono, 2 = stereo)
AUDIO_CHANNELS=1

# ===========================================
# Behavior Settings
# ===========================================

# Play confirmation sounds (true/false)
PLAY_SOUNDS=true

# Log verbosity (1 = errors only, 2 = info, 3 = debug)
LOG_LEVEL=2
